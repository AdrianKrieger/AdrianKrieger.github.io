<!DOCTYPE html>
<html lang="en" class="scroll-smooth">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Adrian Krieger - Robotic Grinding Surface Quality</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <style>
        @import url('https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap');
        body {
            font-family: 'Inter', sans-serif;
            background-color: #0b1120;
            color: #e2e8f0;
            background-image: url('https://images.unsplash.com/photo-1616429532585-f5b2b295c024?q=80&w=1740&auto=format&fit=crop');
            background-size: cover;
            background-position: center top;
            background-attachment: fixed;
            position: relative;
        }
        body::before {
            content: '';
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            background-color: rgba(0, 0, 0, 0.4);
            z-index: -1;
        }
        .nav-link:hover {
            color: #d1d5db;
        }
        .card {
            background-color: rgba(30, 41, 59, 0.7);
            backdrop-filter: blur(8px);
            box-shadow: 0 8px 16px -4px rgba(0, 0, 0, 0.4), 0 4px 8px -2px rgba(0, 0, 0, 0.2);
            transition: transform 0.2s ease-in-out;
            border: 1px solid rgba(148, 163, 184, 0.2);
        }
        .section-header {
            border-bottom: 2px solid #374151; /* slate-700 */
            padding-bottom: 0.5rem;
            margin-bottom: 1.5rem;
        }
        .text-themed-blue { color: #a5b4fc; }
        .text-themed-purple { color: #c4b5fd; }
    </style>
</head>
<body class="antialiased">

    <header class="sticky top-0 bg-slate-900 bg-opacity-60 backdrop-blur-md shadow-lg z-50">
         <nav class="container mx-auto px-6 py-4 flex justify-between items-center">
            <a href="../index.html" class="text-2xl font-bold text-white">Adrian Krieger</a>
            <div class="hidden md:flex space-x-6 text-gray-300 font-medium">
                <a href="../index.html#about" class="nav-link">About</a>
                <a href="projects.html" class="nav-link">Projects</a>
                <a href="#" class="nav-link">Github</a>
                <a href="../index.html#cv-contact" class="nav-link">CV</a>
                <a href="../index.html#cv-contact" class="nav-link">Contact</a>
            </div>
            <button id="mobile-menu-button" class="md:hidden text-gray-300 focus:outline-none">
                <svg class="w-6 h-6" fill="none" stroke="currentColor" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg">
                    <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M4 6h16M4 12h16M4 18h16"></path>
                </svg>
            </button>
        </nav>
        <div id="mobile-menu" class="hidden md:hidden bg-slate-900 bg-opacity-60 backdrop-blur-md shadow-md">
            <div class="flex flex-col items-center py-4 space-y-2 text-gray-300 font-medium">
                <a href="../index.html#about" class="nav-link w-full text-center py-2 hover:bg-slate-800 transition-colors duration-200">About</a>
                <a href="projects.html" class="nav-link w-full text-center py-2 hover:bg-slate-800 transition-colors duration-200">Projects</a>
                <a href="#" class="nav-link w-full text-center py-2 hover:bg-slate-800 transition-colors duration-200">Github</a>
                <a href="../index.html#cv-contact" class="nav-link w-full text-center py-2 hover:bg-slate-800 transition-colors duration-200">CV</a>
                <a href="../index.html#cv-contact" class="nav-link w-full text-center py-2 hover:bg-slate-800 transition-colors duration-200">Contact</a>
            </div>
        </div>
    </header>

    <main class="container mx-auto px-6 py-8 md:py-16">
        <section id="project-one-details" class="py-12 md:py-20 text-center">
            
            <p class="text-lg font-medium text-themed-blue mb-2">Bachelor Thesis (Aerospace Engineering)</p>
            <h1 class="text-4xl md:text-5xl font-bold text-white mb-6">Deep Learning for Automated Surface Quality Assessment in Robotic Grinding</h1>
            <p class="text-xl md:text-2xl text-gray-400 mb-10">Developing a robust dataset and evaluating machine learning viability for in-process quality control of metal components.</p>
            
            <div class="card p-8 rounded-xl max-w-5xl mx-auto text-left space-y-12">
                
                <div class="flex flex-wrap justify-center md:justify-start gap-4 pb-4">
                    <span class="px-3 py-1 bg-slate-800 text-themed-blue text-sm rounded-full font-medium">Deep Learning (DL)</span>
                    <span class="px-3 py-1 bg-slate-800 text-themed-blue text-sm rounded-full font-medium">Computer Vision</span>
                    <span class="px-3 py-1 bg-slate-800 text-themed-blue text-sm rounded-full font-medium">IMRD Structure</span>
                    <span class="px-3 py-1 bg-slate-800 text-themed-blue text-sm rounded-full font-medium">VGG16 & ResNet-18</span>
                </div>

                <div class="flex flex-wrap justify-center md:justify-start space-x-6">
                    <a href="assets/documents/cv.pdf" target="_blank" class="text-themed-blue hover:text-blue-300 transition-colors duration-200 font-bold">Read Full Thesis (PDF) &rarr;</a>
                    <a href="#" class="text-gray-400 hover:text-gray-200 transition-colors duration-200 font-bold">View GitHub &rarr;</a>
                </div>
                
                
                <div id="introduction">
                    <h2 class="text-3xl font-bold text-white section-header">I. Introduction: Social Value & Objective</h2>
                    <div class="text-lg text-gray-300 leading-relaxed space-y-4">
                        <p>
                            Automating the final grinding and finishing step in manufacturing processes is critical due to the rising challenge of finding skilled workers and the overall industry push toward AI and robotics. Current quality control relies on slow, contact-based tactile devices or expensive laser systems, limiting the feasibility of dynamic, in-process measurements.
                        </p>
                        <p>
                            The project objective was to create a preliminary dataset of labeled grinding images and evaluate different Machine Learning (ML) and Deep Learning (DL) approaches to establish a viable future direction for the ROBOTe lab's fully automatic robotic-arm manufacturing solution.
                        </p>
                    </div>
                    
                    <div class="mt-8 mb-4 text-center">
                        <h3 class="text-xl font-semibold text-white mb-4">Workpiece Condition: Before & After Grinding</h3>
                        <div class="w-full mx-auto max-w-3xl">
                             <img src="assets/images/project1_workpiece_progress.jpg" alt="Workpiece surface before and after robotic grinding process" class="w-full h-auto object-cover rounded-md mb-4">
                        </div>
                        <p class="text-sm text-gray-400 mt-2">The workpiece before grinding (left, Rz $\approx 12.7\mu m$) and after 124 iterations (right, Rz $\approx 1.1\mu m$).</p>
                    </div>
                </div>

                <div id="methods">
                    <h2 class="text-3xl font-bold text-white section-header">II. Methods: Data Acquisition & Processing</h2>
                    
                    <h3 class="text-xl font-semibold text-themed-blue mt-4 mb-2">Experimental Setup & Acquisition</h3>
                    <div class="text-lg text-gray-300 leading-relaxed space-y-4">
                        <p>
                            Grinding was performed on a C45 steel workpiece using the KUKA LBR iiwa 7 R800 robotic arm and a prototype EOAT. To ensure the final model was robust to real-world factory conditions, images were acquired under varied circumstances:
                        </p>
                        <ul class="list-disc list-inside space-y-2 pl-4 text-gray-300">
                            <li>**Angles:** Four sets of 3D-printed brackets were used to capture images at $30^{\circ}$, $45^{\circ}$, $60^{\circ}$, and $90^{\circ}$ angles.</li>
                            <li>**Lighting:** Seven unique lux configurations were applied to the $90^{\circ}$ images to test model resilience against variable lighting conditions.</li>
                            <li>**Hardware:** Three different cameras (Canon EOS 50, Allied Vision, Logitech C920) were used to create three separate datasets for comparison.</li>
                        </ul>
                    </div>

                    <div class="mt-8 mb-4 text-center">
                        <h3 class="text-xl font-semibold text-white mb-4">Experimental Setup for Image Acquisition</h3>
                        <div class="w-full mx-auto max-w-3xl">
                            <img src="assets/images/project1_setup_rig.jpg" alt="Photo of the KUKA robot rig, workpiece, and light bar setup" class="w-full h-auto object-cover rounded-md mb-4">
                        </div>
                        <p class="text-sm text-gray-400 mt-2">The experimental rig showing the KUKA arm's EOAT, light bars, and workpiece setup.</p>
                    </div>
                    
                    <h3 class="text-xl font-semibold text-themed-blue mt-4 mb-2">Data Processing Pipeline</h3>
                    <div class="text-lg text-gray-300 leading-relaxed space-y-4">
                        <p>
                            To ensure high data quality, raw images were processed using a custom Python pipeline. This involved automated background cropping via an edge detection algorithm and extending the dataset size by cropping relevant regions up to 24 times per raw image.
                        </p>
                        <p>
                            For labeling, the highest roughness value ($\mathbf{Rz}$) measured by the tactile device was used to ensure the resulting model was conservative—preferring unnecessary additional grinding over producing a faulty part.
                        </p>
                    </div>
                </div>
                
                <div id="results">
                    <h2 class="text-3xl font-bold text-white section-header">III. Results & Evaluation</h2>
                    
                    <h3 class="text-xl font-semibold text-themed-blue mt-4 mb-4">Classification Model Performance</h3>
                    <div class="text-lg text-gray-300 leading-relaxed space-y-4">
                        <p>
                            Experiments with FNN, ResNet-18, and VGG16 Convolutional Neural Networks (CNN) focused on classification accuracy. The optimal settings involved using the VGG16 architecture combined with data augmentation and filtering out images from poor lux configurations.
                        </p>
                    </div>
                    
                    <div class="my-8 flex flex-col lg:flex-row gap-8">
                        <div class="w-full lg:w-1/2">
                            <h3 class="text-lg font-semibold text-white mb-4">Metrics Comparison: Baseline vs. VGG16 (Model 8)</h3>
                            <div class="w-full">
                                <img src="assets/images/project1_metrics_report.png" alt="Classification report for Model 1 and Model 8" class="w-full h-auto object-cover rounded-md mb-4">
                            </div>
                            <p class="text-sm text-gray-400 mt-2">Model 8 achieved significant improvements across all roughness classes (1-3$\mu m$ through 7+$\mu m$) compared to the FNN baseline.</p>
                        </div>
                        <div class="w-full lg:w-1/2">
                            <h3 class="text-lg font-semibold text-white mb-4">ROC Curves & AUC Evaluation</h3>
                            <div class="w-full">
                                <img src="assets/images/project1_roc_curves.png" alt="ROC curves comparing Model 1 and Model 8 performance" class="w-full h-auto object-cover rounded-md mb-4">
                            </div>
                            <p class="text-sm text-gray-400 mt-2">ROC curves showing Model 8's superior performance (Average AUC $\approx 0.97$) compared to the baseline (Average AUC $\approx 0.85$).</p>
                        </div>
                    </div>
                    
                    <h3 class="text-xl font-semibold text-themed-blue mt-8 mb-4">Key Evaluation Findings</h3>
                    <ul class="list-disc list-inside text-lg space-y-2 pl-4 text-gray-300">
                        <li>The best model (VGG16 Model 8) achieved a test accuracy of 82.50%, demonstrating the method's feasibility.</li>
                        <li>A VGG16 regression model achieved a high-precision Mean Absolute Error (MAE) of $0.3328\mu m$ in the $1\mu m-2\mu m$ roughness range.</li>
                        <li>The test accuracy for the $60^{\circ}$ angled images was surprisingly high at $74.00\%$, suggesting viability for applications where $90^{\circ}$ camera access is physically impossible.</li>
                    </ul>
                </div>
                
                <div id="contribution" class="pt-4">
                    <h2 class="text-3xl font-bold text-white section-header">IV. My Contribution & Role</h2>
                    <div class="text-lg text-gray-300 leading-relaxed space-y-4">
                        <p>
                            As the sole researcher for this Bachelor Thesis, my role involved the design, implementation, execution, and analysis of the entire project:
                        </p>
                        <ul class="list-disc list-inside text-lg space-y-2 pl-4 text-gray-300">
                            <li>Experimental Design: Conceptualizing and designing the acquisition setup, including custom 3D-printed brackets for multi-angle image capture.</li>
                            <li>Data Acquisition: Leading the 125 grinding iterations, acquiring the multi-angle and multi-lux image dataset, and conducting the physical tactile roughness measurements.</li>
                            <li>Pipeline Development: Writing all Python scripts for data processing, including automated cropping, FNC generation, and label file creation.</li>
                            <li>ML Implementation: Implementing, training, and analyzing all VGG16 and ResNet-18 classification and regression models.</li>
                        </ul>
                    </div>
                </div>

                <div class="flex flex-wrap justify-center space-x-4 pt-8">
                    <a href="projects.html" class="text-gray-400 hover:text-gray-200 transition-colors duration-200 font-bold">← Back to Projects</a>
                </div>
            </div>
        </section>
    </main>

    <footer class="bg-slate-900 bg-opacity-60 backdrop-blur-md text-white text-center py-6">
        <p>&copy; 2025 Adrian Krieger. All rights reserved.</p>
    </footer>

    <script>
        // Smooth scrolling for navigation links
        document.querySelectorAll('a[href^="#"]').forEach(anchor => {
            anchor.addEventListener('click', function (e) {
                e.preventDefault();
                document.querySelector(this.getAttribute('href')).scrollIntoView({
                    behavior: 'smooth'
                });
                // Close mobile menu after clicking a link
                document.getElementById('mobile-menu').classList.add('hidden');
            });
        });

        // Toggle mobile menu visibility
        document.getElementById('mobile-menu-button').addEventListener('click', function() {
            const menu = document.getElementById('mobile-menu');
            menu.classList.toggle('hidden');
        });
    </script>
</body>
</html>
